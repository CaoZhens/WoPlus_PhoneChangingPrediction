{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import re\n",
    "\n",
    "title = 'woplus'\n",
    "path = '../../sources/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_net = pd.read_table('{}/dataset_2015_filter_net.txt'.format(path), sep='|')\n",
    "df_net_piv = df_net.pivot(index='imsi', columns='mon')\n",
    "df_net_piv.columns = ['net01','net02','net03','net04','net05','net06','net07','net08','net09','net10','net11','net12']\n",
    "\n",
    "df_age = pd.read_table('{}/dataset_2015_filter_age.txt'.format(path), sep='|')\n",
    "df_age_piv = df_age.pivot(index='imsi', columns='mon')\n",
    "df_age_piv.columns = ['age01','age02','age03','age04','age05','age06','age07','age08','age09','age10','age11','age12']\n",
    "\n",
    "df_sex = pd.read_table('{}/dataset_2015_filter_sex.txt'.format(path), sep='|')\n",
    "df_sex_piv = df_sex.pivot(index='imsi', columns='mon')\n",
    "df_sex_piv.columns = ['sex01','sex02','sex03','sex04','sex05','sex06','sex07','sex08','sex09','sex10','sex11','sex12']\n",
    "\n",
    "df_arpu = pd.read_table('{}/dataset_2015_filter_arpu.txt'.format(path), sep='|')\n",
    "df_arpu_piv = df_arpu.pivot(index='imsi', columns='mon')\n",
    "df_arpu_piv.columns = ['arpu01','arpu02','arpu03','arpu04','arpu05','arpu06','arpu07','arpu08','arpu09','arpu10','arpu11','arpu12']\n",
    "\n",
    "df_stream = pd.read_table('{}/dataset_2015_filter_stream.txt'.format(path), sep='|')\n",
    "df_stream_piv = df_stream.pivot(index='imsi', columns='mon')\n",
    "df_stream_piv.columns = ['stream01','stream02','stream03','stream04','stream05','stream06','stream07','stream08','stream09','stream10','stream11','stream12']\n",
    "\n",
    "df_sms = pd.read_table('{}/dataset_2015_filter_sms.txt'.format(path), sep='|')\n",
    "df_sms_piv = df_sms.pivot(index='imsi', columns='mon')\n",
    "df_sms_piv.columns = ['sms01','sms02','sms03','sms04','sms05','sms06','sms07','sms08','sms09','sms10','sms11','sms12']\n",
    "\n",
    "df_talklen = pd.read_table('{}/dataset_2015_filter_talklen.txt'.format(path), sep='|')\n",
    "df_talklen_piv = df_talklen.pivot(index='imsi', columns='mon')\n",
    "df_talklen_piv.columns = ['talklen01','talklen02','talklen03','talklen04','talklen05','talklen06','talklen07','talklen08','talklen09','talklen10','talklen11','talklen12']\n",
    "\n",
    "df_me = pd.read_table('{}/dataset_2015_filter_me.txt'.format(path), sep='|')\n",
    "df_me_piv = df_me.pivot(index='imsi', columns='mon')\n",
    "df_me_piv.columns = ['brand01','brand02','brand03','brand04','brand05','brand06','brand07','brand08','brand09','brand10','brand11','brand12',\\\n",
    "                     'type01','type02','type03','type04','type05','type06','type07','type08','type09','type10','type11','type12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ValueCounts(das, nhead=5):\n",
    "    tmp = pd.value_counts(das).reset_index().rename_axis({'index': das.name}, axis=1)\n",
    "    value = pd.DataFrame(['Value {}'.format(x+1) for x in np.arange(nhead)], index=np.arange(nhead)).join(tmp.iloc[:, 0], how='left').set_index(0).T\n",
    "    freq = pd.DataFrame(['Freq {}'.format(x+1) for x in np.arange(nhead)], index=np.arange(nhead)).join(tmp.iloc[:, 1], how='left').set_index(0).T\n",
    "    nnull = das.isnull().sum()\n",
    "    freqother = pd.DataFrame({das.name: [das.shape[0] - nnull - np.nansum(freq.values), nnull]}, index=['Freq Others','Freq NA']).T\n",
    "    op = pd.concat([value, freq, freqother], axis=1)\n",
    "    return op\n",
    "\n",
    "def Summary(da):\n",
    "    op = pd.concat([pd.DataFrame({'type':da.dtypes, 'nnullCount':da.notnull().sum(axis=0)}), da.describe().T.iloc[:, 1:],\n",
    "          pd.concat(map(lambda i: ValueCounts(da.loc[:,i]), da.columns))], axis=1).loc[da.columns]\n",
    "    op.index.name='columns'\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Feature's Bin with OHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cat_to_bin(das, a = 0.01):\n",
    "    '''Transfrom a categorical column to onehotencoding'''\n",
    "    tmp = pd.value_counts(das)/das.shape[0]\n",
    "    cat = list(tmp.index[tmp > a])\n",
    "    cat.sort()   # 改良：使用cat前对cat进行一次排序，保证顺序一致\n",
    "    enc = OneHotEncoder(n_values = len(cat)+1, sparse = False)\n",
    "    xbin = enc.fit_transform(np.transpose(\n",
    "            [das.astype(\"category\").cat.set_categories(cat).cat.rename_categories(1+np.arange(len(cat))).astype(\"float\").fillna(0).values]))[:,1:]     \n",
    "    dabin = pd.DataFrame(xbin, columns = [\"{}_{}\".format(das.name[:-2], x) for x in cat], index = das.index)    # origin\n",
    "    # dabin = pd.DataFrame(xbin, columns = [\"{}_{}\".format(das.name, x) for x in (1+np.arange(len(cat)))], index = das.index) \n",
    "    if(tmp[tmp <= a].sum() > a):\n",
    "        dabin = pd.concat([dabin, pd.DataFrame({\"{}_Others\".format(das.name[:-2]):das.notnull()-dabin.sum(axis = 1)})], axis = 1)\n",
    "    if(dabin.shape[1] == 2):\n",
    "        dabin = pd.DataFrame({das.name[:-2]: xbin[:,0]}, index = das.index)\n",
    "    return(dabin)\n",
    "\n",
    "def CattoBin(da, a = 0.01):\n",
    "    op = pd.concat(map(lambda i: Cat_to_bin(da.loc[:, i], a), da.columns), axis=1)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Feature's Standardalization with StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SSTraining(da):\n",
    "    ss = StandardScaler().fit(da)\n",
    "    # ss.mean_\n",
    "    # ss.scale_\n",
    "    newColumns = []\n",
    "    for col in da.columns:\n",
    "        newColumns.append(col[:-2])\n",
    "    op = pd.DataFrame(ss.transform(da), index=da.index, columns=newColumns)\n",
    "    return op, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label's Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isChangingStrict(dl):\n",
    "    return len(np.unique(dl))\n",
    "\n",
    "def labelGenerate(df, Mon1, Mon2):\n",
    "    df_phone = df.loc[:,['brand'+Mon1,'type'+Mon1,'brand'+Mon2,'type'+Mon2]]\n",
    "    df_phone_label_strict = df_phone.apply(isChangingStrict, axis=1)\n",
    "    df_phone_label_strict[df_phone_label_strict < 3] = 0\n",
    "    df_phone_label_strict[df_phone_label_strict >=3] = 1\n",
    "    return pd.DataFrame(df_phone_label_strict, columns=['Flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature's Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def selMonAndGenFeat(mon):\n",
    "    featList = df_net_piv.columns.tolist()\n",
    "    df_net_piv_sel = df_net_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_age_piv.columns.tolist()\n",
    "    df_age_piv_sel = df_age_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_sex_piv.columns.tolist()\n",
    "    df_sex_piv_sel = df_sex_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_arpu_piv.columns.tolist()\n",
    "    df_arpu_piv_sel = df_arpu_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_stream_piv.columns.tolist()\n",
    "    df_stream_piv_sel = df_stream_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_sms_piv.columns.tolist()\n",
    "    df_sms_piv_sel = df_sms_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    featList = df_talklen_piv.columns.tolist()\n",
    "    df_talklen_piv_sel = df_talklen_piv.loc[:, map(lambda i: re.findall('\\d{2}',featList[i])[0] == mon, np.arange(len(featList)))]\n",
    "    \n",
    "    return df_net_piv_sel, df_age_piv_sel, df_sex_piv_sel, df_arpu_piv_sel, df_stream_piv_sel, df_sms_piv_sel, df_talklen_piv_sel\n",
    "\n",
    "def featGenerate(mon):\n",
    "    df_net_piv_sel, df_age_piv_sel, df_sex_piv_sel, df_arpu_piv_sel, \\\n",
    "    df_stream_piv_sel, df_sms_piv_sel, df_talklen_piv_sel = selMonAndGenFeat(mon)\n",
    "    \n",
    "    # deal with Category Features\n",
    "    net_catbin = CattoBin(df_net_piv_sel)\n",
    "    age_catbin = CattoBin(df_age_piv_sel)\n",
    "    sex_catbin = CattoBin(df_sex_piv_sel)\n",
    "    arpu_catbin = CattoBin(df_arpu_piv_sel)\n",
    "    stream_catbin = CattoBin(df_stream_piv_sel)\n",
    "    \n",
    "    # deal with Numerical Features\n",
    "    sms_ss, sscaler_sms = SSTraining(df_sms_piv_sel)\n",
    "    talklen_ss, sscaler_talklen = SSTraining(df_talklen_piv_sel)\n",
    "    \n",
    "    # concat\n",
    "    df_features = pd.concat([net_catbin, age_catbin, sex_catbin, arpu_catbin, stream_catbin, sms_ss, talklen_ss], axis=1)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TrainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comment: mon is string\n",
    "def genTrainSet(mon1, mon2):\n",
    "    tsFeat = featGenerate(mon1)\n",
    "    tsLabel = labelGenerate(df_me_piv, mon1, mon2)\n",
    "    op = pd.concat([tsFeat, tsLabel], axis=1)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net</th>\n",
       "      <th>age_17岁以下</th>\n",
       "      <th>age_18-22</th>\n",
       "      <th>age_23-25</th>\n",
       "      <th>age_26-29</th>\n",
       "      <th>age_30-39</th>\n",
       "      <th>age_40-49</th>\n",
       "      <th>age_50-59</th>\n",
       "      <th>age_60以上</th>\n",
       "      <th>sex_不详</th>\n",
       "      <th>...</th>\n",
       "      <th>arpu_250-299</th>\n",
       "      <th>arpu_300及以上</th>\n",
       "      <th>arpu_50-99</th>\n",
       "      <th>stream_0-499</th>\n",
       "      <th>stream_1000-1499</th>\n",
       "      <th>stream_500-999</th>\n",
       "      <th>stream_Others</th>\n",
       "      <th>sms</th>\n",
       "      <th>talklen</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127896</td>\n",
       "      <td>0.487078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.243601</td>\n",
       "      <td>-0.329402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.260130</td>\n",
       "      <td>-0.541977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227071</td>\n",
       "      <td>-0.392208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.260130</td>\n",
       "      <td>-0.561302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   net  age_17岁以下  age_18-22  age_23-25  age_26-29  age_30-39  age_40-49  \\\n",
       "0  0.0        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "1  1.0        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "2  1.0        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "3  1.0        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "4  1.0        0.0        0.0        0.0        0.0        1.0        0.0   \n",
       "\n",
       "   age_50-59  age_60以上  sex_不详  ...   arpu_250-299  arpu_300及以上  arpu_50-99  \\\n",
       "0        0.0       0.0     0.0  ...            0.0          0.0         1.0   \n",
       "1        0.0       0.0     0.0  ...            0.0          0.0         0.0   \n",
       "2        0.0       0.0     0.0  ...            0.0          0.0         0.0   \n",
       "3        0.0       0.0     0.0  ...            0.0          0.0         0.0   \n",
       "4        0.0       0.0     0.0  ...            0.0          0.0         0.0   \n",
       "\n",
       "   stream_0-499  stream_1000-1499  stream_500-999  stream_Others       sms  \\\n",
       "0           1.0               0.0             0.0            0.0 -0.127896   \n",
       "1           1.0               0.0             0.0            0.0 -0.243601   \n",
       "2           1.0               0.0             0.0            0.0 -0.260130   \n",
       "3           1.0               0.0             0.0            0.0 -0.227071   \n",
       "4           1.0               0.0             0.0            0.0 -0.260130   \n",
       "\n",
       "    talklen  Flag  \n",
       "0  0.487078     0  \n",
       "1 -0.329402     0  \n",
       "2 -0.541977     0  \n",
       "3 -0.392208     0  \n",
       "4 -0.561302     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_09 = genTrainSet('09', '10')\n",
    "df_train_10 = genTrainSet('10', '11')\n",
    "df_train_f = pd.concat([df_train_09, df_train_10], axis=0, ignore_index=True)\n",
    "df_train_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m, n = np.shape(df_train_f)\n",
    "X = df_train_f.iloc[:, :(n-1)].values\n",
    "y = df_train_f.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/fanghan/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# np.shape(X_train)\n",
    "# np.shape(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度：0.81939\n",
      "训练集AUC：0.59054\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90    413775\n",
      "          1       0.00      0.00      0.00     91202\n",
      "\n",
      "avg / total       0.67      0.82      0.74    504977\n",
      "\n",
      "验证集准确度：0.82\n",
      "验证集AUC：0.58893\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      1.00      0.90    176951\n",
      "          1       0.00      0.00      0.00     39468\n",
      "\n",
      "avg / total       0.67      0.82      0.74    216419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BaseLine Score\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "yHat = LR.predict(X_train)\n",
    "yScore = LR.predict_proba(X_train)\n",
    "y_testHat = LR.predict(X_test)\n",
    "y_testScore = LR.predict_proba(X_test)\n",
    "print u'训练集准确度：%.5f' % (np.mean(yHat == y_train))\n",
    "print u'训练集AUC：%.5f'% roc_auc_score(y_train, yScore[:,1])\n",
    "print classification_report(y_train, yHat)\n",
    "\n",
    "print u'验证集准确度：%.2f' % (np.mean(y_testHat == y_test)) \n",
    "print u'验证集AUC：%.5f'% roc_auc_score(y_test, y_testScore[:,1])\n",
    "print classification_report(y_test, y_testHat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_11 = genTrainSet('11', '12')\n",
    "df_test_f = df_train_11\n",
    "m, n = np.shape(df_test_f)\n",
    "testX = df_test_f.iloc[:, :(n-1)].values\n",
    "testy = df_test_f.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确度：0.74\n",
      "测试集AUC：0.60646\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      1.00      0.85    267431\n",
      "          1       0.00      0.00      0.00     93267\n",
      "\n",
      "avg / total       0.55      0.74      0.63    360698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testyHat = LR.predict(testX)\n",
    "testyScore = LR.predict_proba(testX)\n",
    "print u'测试集准确度：%.2f' % (np.mean(testyHat == testy)) \n",
    "print u'测试集AUC：%.5f'% roc_auc_score(testy, testyScore[:,1])\n",
    "print classification_report(testy, testyHat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
